{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"ml-transfer-learning-fine-tuning.ipynb","provenance":[],"collapsed_sections":["LqXz_pFE3yAd","Hu3IOMT13yAk"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"enIENu5A33lZ"},"source":["# Hyperparameter Optimization\n","- with Weights and Bias, https://wandb.ai/site\n","- Note that this notebook was originally ran on Kaggle in separate versions. This notebook reflects Version 6, which has the output of XLNet. For the output of BERT and RoBERTa, refer to Version 4 and 5 of this [Kaggle Notebook](https://www.kaggle.com/wushennn/ml-transfer-learning-fine-tuning) \n","- Alternatively, results of hyperparameter tuning over the number of epcohs and learning rate can be visualized in the following links: [BERT](https://wandb.ai/datasiens/bert_original_train/sweeps/5v6557nj?workspace=user-), [RoBERTa](https://wandb.ai/datasiens/roberta_original_train/sweeps/eluhck1w?workspace=user-), [XLNet](https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6?workspace=user-)"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:38:55.675828Z","iopub.execute_input":"2021-11-07T13:38:55.676607Z","iopub.status.idle":"2021-11-07T13:39:33.324470Z","shell.execute_reply.started":"2021-11-07T13:38:55.676508Z","shell.execute_reply":"2021-11-07T13:39:33.323540Z"},"trusted":true,"id":"1JtsX7Pp3x_8","outputId":"99b9f567-7436-4acc-fecf-5f3173178ed0"},"source":["!pip install -qq wandb\n","!pip install -qq transformers\n","!pip install -qq simpletransformers"],"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 21.8.3 requires cupy-cuda114, which is not installed.\ndistributed 2021.7.1 requires dask==2021.07.1, but you have dask 2021.10.0 which is incompatible.\ndask-cudf 21.8.3 requires dask<=2021.07.1,>=2021.6.0, but you have dask 2021.10.0 which is incompatible.\ndask-cudf 21.8.3 requires pandas<1.3.0dev0,>=1.0, but you have pandas 1.3.4 which is incompatible.\nallennlp 2.7.0 requires transformers<4.10,>=4.1, but you have transformers 4.12.3 which is incompatible.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-07T13:39:33.327141Z","iopub.execute_input":"2021-11-07T13:39:33.327451Z","iopub.status.idle":"2021-11-07T13:39:41.676663Z","shell.execute_reply.started":"2021-11-07T13:39:33.327411Z","shell.execute_reply":"2021-11-07T13:39:41.675879Z"},"trusted":true,"id":"uHbHSP5E3yAH"},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score\n","import logging\n","from statistics import mean, mode\n","import wandb\n","from simpletransformers.classification import ClassificationArgs, ClassificationModel"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G6hwvitQ3yAJ"},"source":["## Load Train and Validation Data"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:39:41.679238Z","iopub.execute_input":"2021-11-07T13:39:41.679760Z","iopub.status.idle":"2021-11-07T13:39:41.733812Z","shell.execute_reply.started":"2021-11-07T13:39:41.679722Z","shell.execute_reply":"2021-11-07T13:39:41.733092Z"},"trusted":true,"id":"6khYvEHZ3yAM"},"source":["# Train data: with back translation augmentation\n","train = pd.read_csv('../input/mlproject/original_train.csv')\n","# train.drop(columns=['Unnamed: 0'], inplace=True)\n","\n","# Add 1 to sentiment label, unable to feed negative label (0: negative, 1: neutral, 2: positive)\n","train['sentiment'] = train['sentiment'].apply(lambda x: x + 1)\n","\n","# Validation\n","validation = pd.read_csv('../input/mlproject/validation.csv')\n","validation.drop(columns=['Unnamed: 0', 'index', 'lemmatized and stopwords_removed'], inplace=True)\n","validation['sentiment'] = validation['sentiment'].apply(lambda x: x + 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:39:41.735989Z","iopub.execute_input":"2021-11-07T13:39:41.736282Z","iopub.status.idle":"2021-11-07T13:39:41.751840Z","shell.execute_reply.started":"2021-11-07T13:39:41.736245Z","shell.execute_reply":"2021-11-07T13:39:41.751101Z"},"trusted":true,"id":"TYoAHf_Z3yAO","outputId":"758506dc-8aec-4f60-c08d-aa593a14d29a"},"source":["train.head()"],"execution_count":null,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text  sentiment\n0  should uber use driverless cars to ease safety...          1\n1  oh hai minorityreport is making your driverles...          1\n2  who is responsible if a self driving car gets ...          1\n3  i almost got rear ended by the google car iron...          0\n4  self driving cars will be a hit until the firs...          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>should uber use driverless cars to ease safety...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>oh hai minorityreport is making your driverles...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>who is responsible if a self driving car gets ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i almost got rear ended by the google car iron...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>self driving cars will be a hit until the firs...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:39:41.752926Z","iopub.execute_input":"2021-11-07T13:39:41.754450Z","iopub.status.idle":"2021-11-07T13:39:41.764629Z","shell.execute_reply.started":"2021-11-07T13:39:41.754412Z","shell.execute_reply":"2021-11-07T13:39:41.763809Z"},"trusted":true,"id":"XYwY5o_h3yAP","outputId":"6c4c8c4c-b1cc-463e-a246-e448d421f53f"},"source":["validation.head()"],"execution_count":null,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text  sentiment\n0  i think my timeline is aggressive but they com...          1\n1  google car has no steering wheel or pedals you...          1\n2  saw the google car around pm at byron at golde...          2\n3  is it crazy to think that self driving cars wi...          2\n4  ive moved about in the last twenty minutes the...          2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i think my timeline is aggressive but they com...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>google car has no steering wheel or pedals you...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>saw the google car around pm at byron at golde...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is it crazy to think that self driving cars wi...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ive moved about in the last twenty minutes the...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:39:41.765783Z","iopub.execute_input":"2021-11-07T13:39:41.766403Z","iopub.status.idle":"2021-11-07T13:39:41.773059Z","shell.execute_reply.started":"2021-11-07T13:39:41.766358Z","shell.execute_reply":"2021-11-07T13:39:41.771980Z"},"trusted":true,"id":"4ckpUHpF3yAS","outputId":"a6ae1cb0-a145-4fbb-ddca-2af20e3e3b54"},"source":["print('Dataset shape:')\n","print(train.shape)\n","print(validation.shape)"],"execution_count":null,"outputs":[{"name":"stdout","text":"Dataset shape:\n(5360, 2)\n(670, 2)\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:39:41.774498Z","iopub.execute_input":"2021-11-07T13:39:41.775221Z","iopub.status.idle":"2021-11-07T13:39:42.009926Z","shell.execute_reply.started":"2021-11-07T13:39:41.775162Z","shell.execute_reply":"2021-11-07T13:39:42.009265Z"},"trusted":true,"id":"JYeOA17Q3yAW","outputId":"fc4ae175-b73a-48c6-fcae-0350e3ed40ff"},"source":["# Train distribution\n","train.groupby('sentiment').count().plot.bar()"],"execution_count":null,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:xlabel='sentiment'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:39:42.011000Z","iopub.execute_input":"2021-11-07T13:39:42.011416Z","iopub.status.idle":"2021-11-07T13:39:42.214763Z","shell.execute_reply.started":"2021-11-07T13:39:42.011380Z","shell.execute_reply":"2021-11-07T13:39:42.214033Z"},"trusted":true,"id":"1U88O6LN3yAY","outputId":"2f17166a-40a9-4563-badc-203048df2094"},"source":["# Validation distribution\n","validation.groupby('sentiment').count().plot.bar()"],"execution_count":null,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:xlabel='sentiment'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"XKx8ceJk3yAa"},"source":["## WandB Login\n","Connect to WandB with apikey to use their services"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-04T08:32:32.347345Z","iopub.execute_input":"2021-11-04T08:32:32.347753Z","iopub.status.idle":"2021-11-04T08:32:32.352223Z","shell.execute_reply.started":"2021-11-04T08:32:32.347702Z","shell.execute_reply":"2021-11-04T08:32:32.351183Z"},"trusted":true,"id":"JUYfC79K3yAb"},"source":["# WandB apikey: 8afe8d7e3e0a18ca1854c9fe7f4bbd7c07a3844b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:45:07.682130Z","iopub.execute_input":"2021-11-07T13:45:07.682924Z","iopub.status.idle":"2021-11-07T13:45:15.281644Z","shell.execute_reply.started":"2021-11-07T13:45:07.682884Z","shell.execute_reply":"2021-11-07T13:45:15.280881Z"},"trusted":true,"id":"w3B6edM93yAc","outputId":"6e28ef59-21c9-41c8-8cc3-6e3f8eb623de"},"source":["wandb.login()"],"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ···················\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 19\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"LqXz_pFE3yAd"},"source":["# BERT"]},{"cell_type":"markdown","metadata":{"id":"7d5Kh0px3yAe"},"source":["**BERT Sweep Config**\n","\n","Set up the sweep configuration, in this case, we are using the following parameters:\n","1. **Bayesian search** method\n","2. Evaluating **accuracy** of each model\n","3. Number of training epochs of 2-5 and learning rate of 1e-5 to 4e-4\n","4. Set up early stopping "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:07:28.489472Z","iopub.execute_input":"2021-11-07T11:07:28.490396Z","iopub.status.idle":"2021-11-07T11:07:28.782157Z","shell.execute_reply.started":"2021-11-07T11:07:28.490348Z","shell.execute_reply":"2021-11-07T11:07:28.781249Z"},"trusted":true,"id":"fFbFAEfH3yAe"},"source":["sweep_config = {\n","    \"method\": \"bayes\",  # grid, random\n","    \"metric\": {\"name\": \"accuracy\", \"goal\": \"maximize\"},\n","    \"parameters\": {\n","        \"num_train_epochs\": {\"min\": 2, \"max\": 5},\n","        \"learning_rate\": {\"min\": 1e-5, \"max\": 4e-4},\n","    },\n","    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\": 6,},\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=\"bert_original_train\")\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yrJLhnFP3yAf"},"source":["**BERT Model Arugment**\n","\n","Model is set up with the following arguments, \n","- manual_seed set to 4 to ensure results are reproducible "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:07:36.459029Z","iopub.execute_input":"2021-11-07T11:07:36.460181Z","iopub.status.idle":"2021-11-07T11:07:36.466235Z","shell.execute_reply.started":"2021-11-07T11:07:36.46013Z","shell.execute_reply":"2021-11-07T11:07:36.465496Z"},"trusted":true,"id":"oaftXatW3yAg"},"source":["model_args = ClassificationArgs()\n","model_args.reprocess_input_data = True\n","model_args.overwrite_output_dir = True\n","model_args.evaluate_during_training = True\n","model_args.manual_seed = 4\n","model_args.use_multiprocessing = True\n","model_args.train_batch_size = 32\n","model_args.labels_list = [0, 1, 2]\n","model_args.eval_batch_size = 16\n","model_args.no_cache = True\n","model_args.no_save = True\n","model_args.wandb_project = \"bert_original_train\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QZpNOtb13yAh"},"source":["Define helper function to train the model "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:07:41.265606Z","iopub.execute_input":"2021-11-07T11:07:41.26619Z","iopub.status.idle":"2021-11-07T11:07:41.272653Z","shell.execute_reply.started":"2021-11-07T11:07:41.266155Z","shell.execute_reply":"2021-11-07T11:07:41.271301Z"},"trusted":true,"id":"rWxk5c0e3yAi"},"source":["def model_train_bert():\n","    # Initialize a new wandb run\n","    wandb.init()\n","\n","    # Create a TransformerModel\n","    model = ClassificationModel(\n","        \"bert\",\n","        \"bert-base-uncased\",\n","        num_labels=3,\n","        use_cuda=True,\n","        args=model_args,\n","        sweep_config=wandb.config,\n","    )\n","\n","    # Train the model\n","    model.train_model(\n","        train,\n","        eval_df=validation,\n","        accuracy=lambda truth, predictions: accuracy_score(\n","            truth, [round(p) for p in predictions]\n","        ),\n","    )\n","    \n","    # Sync wandb\n","    wandb.join()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A9CkOBf_9E3k"},"source":["Call WandB.agent to run the helper function. \n","\n","WandB.agent is a generic agent entrypoint, used for CLI or jupyter. \n","\n","Results of the sweep can be viewed: https://wandb.ai/datasiens/bert_original_train/sweeps/5v6557nj?workspace=user-"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:07:45.243548Z","iopub.execute_input":"2021-11-07T11:07:45.244031Z","iopub.status.idle":"2021-11-07T13:33:21.08988Z","shell.execute_reply.started":"2021-11-07T11:07:45.243993Z","shell.execute_reply":"2021-11-07T13:33:21.08906Z"},"trusted":true,"id":"oDzYpk7j3yAj"},"source":["wandb.agent(sweep_id, model_train_bert)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hu3IOMT13yAk"},"source":["# Roberta"]},{"cell_type":"markdown","metadata":{"id":"puVSFZQT3yAk"},"source":["**Roberta Sweep Config**\n","\n","Set up the sweep configuration, in this case, we are using the following parameters:\n","1. **Bayesian search** method\n","2. Evaluating **accuracy** of each model\n","3. Number of training epochs of 2-10 and learning rate of 1e-5 to 4e-4\n","4. Set up early stopping "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T08:02:59.947398Z","iopub.execute_input":"2021-11-07T08:02:59.947703Z","iopub.status.idle":"2021-11-07T08:03:00.246444Z","shell.execute_reply.started":"2021-11-07T08:02:59.94767Z","shell.execute_reply":"2021-11-07T08:03:00.245703Z"},"trusted":true,"id":"ruy9vExP3yAl"},"source":["sweep_config = {\n","    \"method\": \"bayes\", \n","    \"metric\": {\"name\": \"accuracy\", \"goal\": \"maximize\"},\n","    \"parameters\": {\n","        \"num_train_epochs\": {\"min\": 2, \"max\": 10},\n","        \"learning_rate\": {\"min\": 1e-5, \"max\": 4e-4},\n","    },\n","    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\": 5,},\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=\"roberta_original_train\")\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w36BwbJb3yAm"},"source":["**Roberta Model Arguments**\n","\n","Model is set up with the following arguments, \n","- manual_seed set to 4 to ensure results are reproducible "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T08:03:33.336168Z","iopub.execute_input":"2021-11-07T08:03:33.337205Z","iopub.status.idle":"2021-11-07T08:03:33.343167Z","shell.execute_reply.started":"2021-11-07T08:03:33.337159Z","shell.execute_reply":"2021-11-07T08:03:33.342471Z"},"trusted":true,"id":"v6NwhROF3yAn"},"source":["model_args = ClassificationArgs()\n","model_args.reprocess_input_data = True\n","model_args.overwrite_output_dir = True\n","model_args.evaluate_during_training = True\n","model_args.manual_seed = 4\n","model_args.use_multiprocessing = True\n","model_args.train_batch_size = 32\n","model_args.labels_list = [0, 1, 2]\n","model_args.eval_batch_size = 16\n","model_args.no_cache = True\n","model_args.no_save = True\n","model_args.wandb_project = \"roberta_original_train\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qPiTNJkW9H6t"},"source":["Define helper function to train the model"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T08:03:36.337368Z","iopub.execute_input":"2021-11-07T08:03:36.338157Z","iopub.status.idle":"2021-11-07T08:03:36.344382Z","shell.execute_reply.started":"2021-11-07T08:03:36.338117Z","shell.execute_reply":"2021-11-07T08:03:36.343678Z"},"trusted":true,"id":"54tqBwu63yAo"},"source":["def model_train():\n","    # Initialize a new wandb run\n","    wandb.init()\n","\n","    # Create a TransformerModel\n","    model = ClassificationModel(\n","        \"roberta\",\n","        \"roberta-base\",\n","        num_labels=3,\n","        use_cuda=True,\n","        args=model_args,\n","        sweep_config=wandb.config,\n","    )\n","\n","    # Train the model\n","    model.train_model(\n","        train,\n","        eval_df=validation,\n","        accuracy=lambda truth, predictions: accuracy_score(\n","            truth, [round(p) for p in predictions]\n","        ),\n","    )\n","    \n","    # Sync wandb\n","    wandb.join()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W27AQzr_9iBB"},"source":["Call WandB.agent to run the helper function. \n","\n","WandB.agent is a generic agent entrypoint, used for CLI or jupyter. \n","\n","Results of the sweep can be viewed: https://wandb.ai/datasiens/roberta_original_train/sweeps/eluhck1w?workspace=user-"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T08:03:37.742301Z","iopub.execute_input":"2021-11-07T08:03:37.743148Z","iopub.status.idle":"2021-11-07T11:06:15.576529Z","shell.execute_reply.started":"2021-11-07T08:03:37.743098Z","shell.execute_reply":"2021-11-07T11:06:15.575795Z"},"trusted":true,"id":"0M__LKiF3yAo"},"source":["wandb.agent(sweep_id, model_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"75XqqC9G3yAp"},"source":["# XLNet\n","List of community models for XLNet can be found on [Hugging Face](https://huggingface.co/models?sort=downloads&search=xlnet)\n","\n","We will use the most popular **xlnet-base-cased**"]},{"cell_type":"markdown","metadata":{"id":"qv6sqUH9_IeA"},"source":["**XLNet Sweep Config**\n","\n","Set up the sweep configuration, in this case, we are using the following parameters:\n","1. **Bayesian search** method\n","2. Evaluating **accuracy** of each model\n","3. Number of training epochs of 2-6 and learning rate of 1e-5 to 4e-4\n","4. Set up early stopping "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:45:30.465350Z","iopub.execute_input":"2021-11-07T13:45:30.466071Z","iopub.status.idle":"2021-11-07T13:45:30.851344Z","shell.execute_reply.started":"2021-11-07T13:45:30.466032Z","shell.execute_reply":"2021-11-07T13:45:30.850593Z"},"trusted":true,"id":"ORXJlzVk3yAp","outputId":"1267950e-4f07-4ffc-90a6-59447642da00"},"source":["sweep_config = {\n","    \"method\": \"bayes\",  # grid, random\n","    \"metric\": {\"name\": \"accuracy\", \"goal\": \"maximize\"},\n","    \"parameters\": {\n","        \"num_train_epochs\": {\"min\": 2, \"max\": 6},\n","        \"learning_rate\": {\"min\": 1e-5, \"max\": 4e-4},\n","    },\n","    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\": 5,},\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=\"xlnet_original_train\")\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)"],"execution_count":null,"outputs":[{"name":"stdout","text":"Create sweep with ID: bylsapm6\nSweep URL: https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"IWVim_ZT_QgU"},"source":["**XLNet Model Arguments**\n","\n","Model is set up with the following arguments, \n","- manual_seed set to 4 to ensure results are reproducible "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:46:38.782470Z","iopub.execute_input":"2021-11-07T13:46:38.783228Z","iopub.status.idle":"2021-11-07T13:46:38.788395Z","shell.execute_reply.started":"2021-11-07T13:46:38.783178Z","shell.execute_reply":"2021-11-07T13:46:38.787635Z"},"trusted":true,"id":"ahmIx7xU3yAq"},"source":["model_args = ClassificationArgs()\n","model_args.reprocess_input_data = True\n","model_args.overwrite_output_dir = True\n","model_args.evaluate_during_training = True\n","model_args.manual_seed = 4\n","model_args.use_multiprocessing = True\n","model_args.train_batch_size = 32\n","model_args.labels_list = [0, 1, 2]\n","model_args.eval_batch_size = 16\n","model_args.no_cache = True\n","model_args.no_save = True\n","model_args.wandb_project = \"xlnet_original_train\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vnGmNgDs9Np6"},"source":["Define helper function to train the model"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:46:45.206793Z","iopub.execute_input":"2021-11-07T13:46:45.207046Z","iopub.status.idle":"2021-11-07T13:46:45.212393Z","shell.execute_reply.started":"2021-11-07T13:46:45.207017Z","shell.execute_reply":"2021-11-07T13:46:45.211699Z"},"trusted":true,"id":"qIm6yF6C3yAr"},"source":["def model_train_xlnet():\n","    # Initialize a new wandb run\n","    wandb.init()\n","\n","    # Create a TransformerModel\n","    model = ClassificationModel(\n","        \"xlnet\",\n","        \"xlnet-base-cased\",\n","        num_labels=3,\n","        use_cuda=True,\n","        args=model_args,\n","        sweep_config=wandb.config,\n","    )\n","\n","    # Train the model\n","    model.train_model(\n","        train,\n","        eval_df=validation,\n","        accuracy=lambda truth, predictions: accuracy_score(\n","            truth, [round(p) for p in predictions]\n","        ),\n","    )\n","    \n","    # Sync wandb\n","    wandb.join()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MnrnH5YG-DGS"},"source":["Call WandB.agent to run the helper function. \n","\n","WandB.agent is a generic agent entrypoint, used for CLI or jupyter. \n","\n","Results of the sweep can be viewed: https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6?workspace=user-"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-11-07T13:46:50.398833Z","iopub.execute_input":"2021-11-07T13:46:50.399387Z","iopub.status.idle":"2021-11-07T16:18:28.111265Z","shell.execute_reply.started":"2021-11-07T13:46:50.399348Z","shell.execute_reply":"2021-11-07T16:18:28.110383Z"},"trusted":true,"colab":{"referenced_widgets":["ce4f4a2cf66d4caf8ba1d648cb4ad6bf","d74c6c3a1bc34711b9a81a3bf14865a9","a62372b75a7d42b983114f413b79390b","500f4e6591ab43fdb00fae44057911c0","1aaba40bf4ff4941838bbe873b8795fe","18c84244d81f45a49baedd5bba949f5e","f16a45b38db54866a9c9bb2044cae090","827f12174c6a42688fee1203f7a7a7f1","6f9c4eaf0fb348429166c1b1f9716501","fc1ab42b54eb46b29e97937791899062","","324148eab13148908308de293531f9e6","1ce089ae7ec84a6081f1af4d5e5df350","52ee77fc389441ee975cbe306267f553","b1b059861653472388e6b0fb701349f8","dadc8b8decf241fdb05461a375ca1a58","38b9ea6741134290b7d8577f049ba87c","e15d9028b4264f65b154c4379c27052b","1afc18886e094598bd08bfef682bb072","771cecf46f1343bc80181367f8bd03a3","d70db4865eb1402c83d0720fe86ba6db","af7fc5082a174c778a47c1dbfa34789b","3bfb740bca3a48acba8769860bf48b50","962b5ed212a44cfb9e3ec1724a79712a","e9fc49bf673b4a2aa33a85505d836fd2","a68530cc3ae74753b0ab117b67c44f6b","910fe00b2dca4698bab9de96dd0684cc","9bc58328eb524f60a995900f1efbf070","ea1f3f4401d5419da355265795ad3ecc","d2ca895b3607460490a54a86096698f8","3b6d03e6931b4b6497a83452a78c8726","7cddddaf9846416fbc10d5f50bfdae8f","240c17c6f38f4ad3b581556446c0aeee","6c6bee95817240b3b27a8ba88778078d","7cfa27b096574d5581ae0866630b364b","ceea55b2126b419591022bc696834534","a3a0ee1395d24f14bd4253f6f5004522","4d776116e646452daa174b64074ab4a2","43ed8ae97701406e89fcd1b345907482","84b7b39d39ef4f8694af4a165b6569e2","5b4f01ae3cd5407c92d02fe9a457864c","a0759e80df0047029de906b4366ce21a","0f9bef3df75a4a23a74dfc262a65cc24","5d0ad77b120e432b9c47e0b396d5e079","41c7c2121024456cafc27cbad32889f0","c0ee4cdaa52043b1921518fe682ee963","bb00b27452b84dd6a8d83c3570401574","7a607aa71cae401ebb3d941a1b73f0bf","72406ea0376b4e11941cf318b92fcddf","d536bcb7462a4c11a04167f2485f3355","945e19b57c3641d9a5f889fe16d31b38","209c56d90b7a41989b7b8aec4796bc5c","a3e35ccc991b49e6abc3888e68ae348e","e0c8725c92d742cf80e289c65cd68858","f234abd25e6b4a889531fcb56cb7fe1d","5b00cfe447504c999fa2ebd268bf13c0","8eeab5be10a14feda595afcda68d1716","6d08943f095b4961828e3fbe54333747","08b240ede8ed41f2842812023c16c65d","a85862485db042c0bd29481bb6107fe7","1a00639e9257452ca105f3b258b610d8","ba6e6388b42d4b5381cee84c051bf172","05120388f7e64d5fbbf2d92b1190335b","19dae35c7309409985a3a6dbf9a653c1","33376f3583664ea396ab287506d035f7","7b0e7732279c4152bf496366a7add616","8a3471446171430483d2b6f6f2a4da53","d078f341ab44468a90d85eadc8ad0853","ac8e8684f4d84de58550894cc408ae31","6172f9f5d4cb42faa67aa8c0e390bf36","a9c39855101e43ccb8c74c0a4de05753","641ae07aefc340989c1f527552060d88","abcce16897fa45ef9c3126f3b5b1a10d","e470b19cfe3348a39227c3912c59fae2","ab0c93d713da4aa2b94e69a544f23a15","588e471019fe4466a02e831196880d8d","3f7c2199146941fab7e2eb2e003a747d","ae23f6f3c33b4c8190b93457617cdd85","34f3ecb9865c4e9d95808e2418428d2d","74d257ab006c4d9aa1d77e2530c1eabb","e616b318e14141bfbf63c2c966d1add2","15822d69ea3a4f0492138759c3e4bb76","6dbf85ef089549d2ba7df75733bc85a7","1ac5a03e03f74c5496718ca80ca28f25","c7ce726740f647e28966e66ceb28b6b2","1068beecd1e942dfab100d03bfed2cb3","787d998ee8584456b1b3f4fe42898747","8dec462fead04154942ca7bd5b98e8cb","825f10e357de444b89cb43d96b8e68c6","0e5d617522e8408b9487d03ed26e5db2","fae629d335be419d9088140d1aeb1f0a","1ceab823d13146aca3c0c69ee0fae81a","54a008aa2c404b1ea22d878635099ddb","924c4b3a55e64e03afc3316274889f8b","6adedc9e85e34998ad65fd613ca20b34","5b1adacdefe44f61b666d5dc6152b460","7f96192e1cdc4be49ab8e951fdedea23","6ff778698f144d8b9523e616c29df6b5","621f998ac7d64c78b84e6fc8c949415e","fe1e9580d80c471ebf2e9db14c2aace2","1dcbede5d34349748b54f19973140873","e1c7336082a64874902f05b63587a2e1","6bf751ec5fa24d6e896b5bf8df443deb","4deb647aebed4a1193466e55ff31e036","9428e9e095b34184a07c3d2bdb555691","645cb45f38ad4acc9ddc5b06cf521018","f66b9ef071a7459583c21fa6f6879da4","f448b11efbe847cf9d4a595cfdf784c7","ff167101ecbc4e00a096257447838cc6","b22dc5e5aad849baba6719ff17b11fce","7b3fae0ee6bb4466a700972cd1e37f6d","f339ea2bf209427a8ed1caab31529157","cc67ec702deb4dd9bfe36da909c1de2a","49a2f604e8d94377a02aeb2160f57ab2","07feda05ca554545a8089ff50ccd352b","a6bfd3ae1e2d4161a4ff43ded91c9187","6285e8ee07bd452fbff64ee11a6e917a","f3832b45069b486996b566b7b7176a03","00d6fdc21e654db4b5d022582d2a939a","e61f0eb7a0a242c2803d2236dc7124cb","b0cf78f9b02c4016a838fd84abb6d442","be12e44f972f4ab8abe68ee5c83d83c8","84582b50ec1546c094ae3eda4b9d935b","00a192d85ad44f2d97a3ee5ba25805b4","287c43812c9a4b44921abd44e81e90a5","913479c71a934e499282023d089cad2e","fd2cfb1c712d4da2839cfd8c280fccf7","2c57e99c96a94458a28aa2f6718aa200","aae777d1de2b4c26b6811ba69ab92198","a7402504b0f34cda9ad66992aac634c4","d656165745c048d6acca7c5a5a4696a1","24b84f9d13fd4f09bdcb2850b9550098","5592c6a3f0c64bff8eacf425063e7ad5","895aa88a2b4c4489a70b515fff25cc7c","ef4a203085ad466b88f13b57f5039113","38baaf4293ea430bb4f122ca8ea9ffa0","f9935ca38ef64e61bff55ef184b7263e","61f32a0f01064076b89a07aafb934060","c5d880f7a3c244d991c7831efb0c8fce","16884bd1813e4b25997b2e8928f5e517","de86b052d7144aae80ec76067c565054","f1729acd14664e3c85e564ea76770bad","c9deee9fd9fc4eba9fa956f45514f00d","5ed0c1f082b048f996d09c547d94adf1","5c4711da8f0f457799b3913bee152390","6e919384363b4dadb09852628bf84292","85a72141667f449cbdb91c82de955e78","b047c1c30845454498017b6848b86371","de4d3b4991ee40d190e984216a5a0ec3","8a44e1a6e592495d9027b1014907747d","04017529aa7b47c5ae268cbb0ce0d844","f82c024663474adcaf9ea74ba6f4871c","32e0d834b684497894733ff6c7d6f375","0c71477159924570a678c5d338b91976","f26665c6062a42bf94ed4de023fdea24","fdebe890769143939624f2095cda74e7","0d3bdaec431c46bb86b71d6ccef0af27","6e8d5c054435482e82fb01c7dfa70289","80617a5131e549f4b963d0077258484c","2cfa175d5c6d4caa95fd000cb27cea62","c8252571ee8b4407936f9662e959c8d3","e4e1c8703ed040a5a2b80a2d611645f2","6899c238282d4d77a7da7888ae2eff18","f7f501a2e7154ee38dc623a872872a1d","5dc7ff7fe80348e6980b4f914099893e","42d60b554b2e4d898e33a6cd8eee69f2","f665ca0d597a48e4af172defb6230f71","645628f27fd7495ebd5ab1a34682b4b5","cf617822d2e64d1bb78e8014337485d2","f2af00fb8c504fc3874f80c65569f75a","63a294a7d2304857ba1312a82793e741","0a550324cb9d421aba7d19b66ce41251","982cd870f9d14a35bd659c43ace1fb2a","e3ecea0fecf34bab980945a117c2f7b6","03d605eb4d0041a39f172f23f74cc259","3f1c7b18b1e547a8bf38d6e653326557","19cee17489494edb939edab627ed06da","711e5a24ef0045c8a1f551316a4d12c2","9a7c6f9cc87640ccaf26a07f9d97bba5","164bef03bced493f81f89637c95dcbca","425636a3d3f041599e8914b3e13c7617","06e133eb4a6a4e65bcb15a932cf21f1d","fb98b6e3fef14001a0380a3386665d29","7c4c9a3694154441a5ee381325751a45","fdd0afdbc9194e9f84f672fbe8a27a21","96d00e2b327a4e0c98f3f75e1d90e813","65f96fc259814e91875ace412d95394c","c5a4e47e630d41d3affd3ef282945231","6df2368c7dfb4647b730c5181f24d3eb","2c4ac0139c2842dbb77fe35935fb1d94","ad158814bc8b44e8ad75287daac426fd","2ad9b93b7220483da1c1fc8ad9d4d8e9","6e18b9a82939491f888d83cfd116a002","b5423d102a6d4d4597f22b64a5e872e2","8f1667fe41ca47169bade642bcca6452","0a066d8db5ec4e218e24f505e29bf3a4","d37facac3d5b4049b246725083b74f8d","5c74b6d32c1c4945b6067c32964148c7","3fe54e5781264539af73a53f1ac0575f","0e7f1ca20c3349e18c546165d148b9f7","508829aae36442dfa0b2e498ff63230f","2e8096d6f2704123af40abbd1f011367","4c48b536cd254ad7807c541dd6a446d5","f9eff8f28bc34fc099eb11968a69f140","48bdf5cd14a043af87f508786c0dd74c","50ea961a871b4b0799c4b0b428bbfbe1","c0989230cb20430d99682dd90736fa97","f587afe58c71434db0e134bd373a60c7","533666aebf1746fbb4a838c5c293e0ec","99da6dece41f450f9cd3c834b2bf8bc5","778c7614e4fa4f7a8d17a1e42fc5af66","4c4631d7b30f42adb94a3308f767a80d","358deadbfba24782bba63f84d0676bef","d722a3d129374d0c86d2878d9abc1877","8626305ea5d34ea29095bf9739465ec7","d00230a85847434393dbabcd998b073c","6acbf65a6a344c55ad9271f596b8d86c","926df985eb2c43f8999956e591cf5fc4","f523e2f04e9146cb960447883ce27972","7916009962b349edb6856fa1ec8b4cf3","23e831da67444eea8ac3e5202afdc274","d4feb02fc9ba4b9790cf11fd41edb935","99c5c9bfdd5540d1b7094475627fe252","1e6b7ecc978c4d87a0cb30951796fa06","b3d8e043404047f1a1b1d0f3f63404fa","afff0e58b2ac445681baf2c733868569","5ffc4a1b6845483788d8ec3b7ff21c1f","fcb8c921229642fda2ec484ea93af591","e8dfdda37a2f4cee83eba8bf100438c6","46828e5d0d7e44b9b07c9e0075e0c01a","c001c7e68bda4997ac8bf7a694db723a","16e63f6c42b7402eb9b8fc112e8ae64c"]},"id":"WGSB1vTu3yAr","outputId":"32736590-f370-42aa-efe7-3ec3cb0d738a"},"source":["wandb.agent(sweep_id, model_train_xlnet)"],"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3hf2bkrl with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.4070228708911732e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdatasiens\u001b[0m (use `wandb login --relogin` to force relogin)\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/3hf2bkrl\" target=\"_blank\">treasured-sweep-1</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4f4a2cf66d4caf8ba1d648cb4ad6bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74c6c3a1bc34711b9a81a3bf14865a9"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a62372b75a7d42b983114f413b79390b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500f4e6591ab43fdb00fae44057911c0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py:586: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aaba40bf4ff4941838bbe873b8795fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c84244d81f45a49baedd5bba949f5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f16a45b38db54866a9c9bb2044cae090"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py:922: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  model.parameters(), args.max_grad_norm\n/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py:1427: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"827f12174c6a42688fee1203f7a7a7f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f9c4eaf0fb348429166c1b1f9716501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc1ab42b54eb46b29e97937791899062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 457... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▃▂▆▆▁█</td></tr><tr><td>accuracy</td><td>▁█</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁█</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.85576</td></tr><tr><td>accuracy</td><td>0.74925</td></tr><tr><td>eval_loss</td><td>0.62675</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.53712</td></tr><tr><td>train_loss</td><td>0.99932</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">treasured-sweep-1</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/3hf2bkrl\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/3hf2bkrl</a><br/>\nFind logs at: <code>./wandb/run-20211107_134652-3hf2bkrl/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ohsnky21 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.424577122953353e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/ohsnky21\" target=\"_blank\">crisp-sweep-2</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"324148eab13148908308de293531f9e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ce089ae7ec84a6081f1af4d5e5df350"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52ee77fc389441ee975cbe306267f553"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b059861653472388e6b0fb701349f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dadc8b8decf241fdb05461a375ca1a58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38b9ea6741134290b7d8577f049ba87c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 663... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▄▅█▆▁█</td></tr><tr><td>accuracy</td><td>▁█</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.76481</td></tr><tr><td>accuracy</td><td>0.76567</td></tr><tr><td>eval_loss</td><td>0.58058</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.56271</td></tr><tr><td>train_loss</td><td>0.58471</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">crisp-sweep-2</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/ohsnky21\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/ohsnky21</a><br/>\nFind logs at: <code>./wandb/run-20211107_135051-ohsnky21/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xqwf78dx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002244721323507937\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/xqwf78dx\" target=\"_blank\">playful-sweep-3</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e15d9028b4264f65b154c4379c27052b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1afc18886e094598bd08bfef682bb072"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"771cecf46f1343bc80181367f8bd03a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d70db4865eb1402c83d0720fe86ba6db"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af7fc5082a174c778a47c1dbfa34789b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bfb740bca3a48acba8769860bf48b50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"962b5ed212a44cfb9e3ec1724a79712a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9fc49bf673b4a2aa33a85505d836fd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a68530cc3ae74753b0ab117b67c44f6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"910fe00b2dca4698bab9de96dd0684cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 857... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▂▃▅▃▆█▇▅▅▄▃▃</td></tr><tr><td>accuracy</td><td>▁▁▁▁</td></tr><tr><td>eval_loss</td><td>▇█▁▁</td></tr><tr><td>global_step</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇██</td></tr><tr><td>lr</td><td>█▇▇▆▆▅▅▄▃▃▂▂▁</td></tr><tr><td>mcc</td><td>▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁▆█▇</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.84342</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87208</td></tr><tr><td>global_step</td><td>672</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.97031</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">playful-sweep-3</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/xqwf78dx\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/xqwf78dx</a><br/>\nFind logs at: <code>./wandb/run-20211107_135431-xqwf78dx/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ni9xbikx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010255473530061908\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/ni9xbikx\" target=\"_blank\">curious-sweep-4</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bc58328eb524f60a995900f1efbf070"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea1f3f4401d5419da355265795ad3ecc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2ca895b3607460490a54a86096698f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b6d03e6931b4b6497a83452a78c8726"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cddddaf9846416fbc10d5f50bfdae8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"240c17c6f38f4ad3b581556446c0aeee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 1188... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▇█▅▄█</td></tr><tr><td>accuracy</td><td>█▁</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.83216</td></tr><tr><td>accuracy</td><td>0.73284</td></tr><tr><td>eval_loss</td><td>0.67554</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.50489</td></tr><tr><td>train_loss</td><td>0.51765</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">curious-sweep-4</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/ni9xbikx\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/ni9xbikx</a><br/>\nFind logs at: <code>./wandb/run-20211107_140129-ni9xbikx/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 67zlueto with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.558427544161275e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/67zlueto\" target=\"_blank\">kind-sweep-5</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c6bee95817240b3b27a8ba88778078d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cfa27b096574d5581ae0866630b364b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceea55b2126b419591022bc696834534"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a0ee1395d24f14bd4253f6f5004522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d776116e646452daa174b64074ab4a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43ed8ae97701406e89fcd1b345907482"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 1386... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▃█▆▁▅</td></tr><tr><td>accuracy</td><td>▁█</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁█</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.73212</td></tr><tr><td>accuracy</td><td>0.76119</td></tr><tr><td>eval_loss</td><td>0.58653</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.5599</td></tr><tr><td>train_loss</td><td>0.74061</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">kind-sweep-5</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/67zlueto\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/67zlueto</a><br/>\nFind logs at: <code>./wandb/run-20211107_140507-67zlueto/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lqo81z4q with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.978449708925588e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/lqo81z4q\" target=\"_blank\">sunny-sweep-6</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84b7b39d39ef4f8694af4a165b6569e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b4f01ae3cd5407c92d02fe9a457864c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0759e80df0047029de906b4366ce21a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f9bef3df75a4a23a74dfc262a65cc24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d0ad77b120e432b9c47e0b396d5e079"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41c7c2121024456cafc27cbad32889f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 1582... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▃▆▆▁█</td></tr><tr><td>accuracy</td><td>▁█</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.88576</td></tr><tr><td>accuracy</td><td>0.75373</td></tr><tr><td>eval_loss</td><td>0.60566</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.54816</td></tr><tr><td>train_loss</td><td>0.59697</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">sunny-sweep-6</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/lqo81z4q\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/lqo81z4q</a><br/>\nFind logs at: <code>./wandb/run-20211107_140846-lqo81z4q/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tf8crnac with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.444681210788344e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/tf8crnac\" target=\"_blank\">elated-sweep-7</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ee4cdaa52043b1921518fe682ee963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb00b27452b84dd6a8d83c3570401574"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a607aa71cae401ebb3d941a1b73f0bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72406ea0376b4e11941cf318b92fcddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d536bcb7462a4c11a04167f2485f3355"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945e19b57c3641d9a5f889fe16d31b38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 1776... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▂▆▅▁█</td></tr><tr><td>accuracy</td><td>▁█</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁█</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.92135</td></tr><tr><td>accuracy</td><td>0.7597</td></tr><tr><td>eval_loss</td><td>0.58871</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.54955</td></tr><tr><td>train_loss</td><td>0.66235</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">elated-sweep-7</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/tf8crnac\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/tf8crnac</a><br/>\nFind logs at: <code>./wandb/run-20211107_141225-tf8crnac/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 15toe3kt with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.931103040131295e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/15toe3kt\" target=\"_blank\">worthy-sweep-8</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209c56d90b7a41989b7b8aec4796bc5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3e35ccc991b49e6abc3888e68ae348e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0c8725c92d742cf80e289c65cd68858"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f234abd25e6b4a889531fcb56cb7fe1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b00cfe447504c999fa2ebd268bf13c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eeab5be10a14feda595afcda68d1716"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 1967... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▃▂▅▇▁█</td></tr><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁█</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.86065</td></tr><tr><td>accuracy</td><td>0.75373</td></tr><tr><td>eval_loss</td><td>0.59888</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.54783</td></tr><tr><td>train_loss</td><td>0.70122</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">worthy-sweep-8</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/15toe3kt\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/15toe3kt</a><br/>\nFind logs at: <code>./wandb/run-20211107_141604-15toe3kt/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fsb3sycf with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.5961355884917234e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/fsb3sycf\" target=\"_blank\">elated-sweep-9</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d08943f095b4961828e3fbe54333747"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08b240ede8ed41f2842812023c16c65d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a85862485db042c0bd29481bb6107fe7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a00639e9257452ca105f3b258b610d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba6e6388b42d4b5381cee84c051bf172"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05120388f7e64d5fbbf2d92b1190335b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 2161... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▃▄██▁▆</td></tr><tr><td>accuracy</td><td>▁█</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.75112</td></tr><tr><td>accuracy</td><td>0.73582</td></tr><tr><td>eval_loss</td><td>0.6274</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.51198</td></tr><tr><td>train_loss</td><td>0.68014</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">elated-sweep-9</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/fsb3sycf\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/fsb3sycf</a><br/>\nFind logs at: <code>./wandb/run-20211107_141943-fsb3sycf/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0oid5pyx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010647636093532612\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/0oid5pyx\" target=\"_blank\">toasty-sweep-10</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19dae35c7309409985a3a6dbf9a653c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33376f3583664ea396ab287506d035f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b0e7732279c4152bf496366a7add616"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a3471446171430483d2b6f6f2a4da53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d078f341ab44468a90d85eadc8ad0853"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac8e8684f4d84de58550894cc408ae31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6172f9f5d4cb42faa67aa8c0e390bf36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c39855101e43ccb8c74c0a4de05753"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 2360... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▂▃▃▁▅██▄▄</td></tr><tr><td>accuracy</td><td>▁▁▁</td></tr><tr><td>eval_loss</td><td>█▁▆</td></tr><tr><td>global_step</td><td>▁▂▃▃▃▄▅▅▆▆▇██</td></tr><tr><td>lr</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>mcc</td><td>▁▁▁</td></tr><tr><td>train_loss</td><td>▁▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.91877</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87807</td></tr><tr><td>global_step</td><td>504</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.06532</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">toasty-sweep-10</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/0oid5pyx\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/0oid5pyx</a><br/>\nFind logs at: <code>./wandb/run-20211107_142323-0oid5pyx/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v0owdq44 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002865826730341756\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/v0owdq44\" target=\"_blank\">cerulean-sweep-11</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"641ae07aefc340989c1f527552060d88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abcce16897fa45ef9c3126f3b5b1a10d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e470b19cfe3348a39227c3912c59fae2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab0c93d713da4aa2b94e69a544f23a15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"588e471019fe4466a02e831196880d8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7c2199146941fab7e2eb2e003a747d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 2627... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▄▂▆▇▁█</td></tr><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.96446</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87245</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.00372</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">cerulean-sweep-11</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/v0owdq44\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/v0owdq44</a><br/>\nFind logs at: <code>./wandb/run-20211107_142843-v0owdq44/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rgrbldxn with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001703255422229328\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/rgrbldxn\" target=\"_blank\">cool-sweep-12</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae23f6f3c33b4c8190b93457617cdd85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34f3ecb9865c4e9d95808e2418428d2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74d257ab006c4d9aa1d77e2530c1eabb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e616b318e14141bfbf63c2c966d1add2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15822d69ea3a4f0492138759c3e4bb76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dbf85ef089549d2ba7df75733bc85a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 2817... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▇▅▂█</td></tr><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.92325</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.83502</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>2e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.8668</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">cool-sweep-12</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/rgrbldxn\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/rgrbldxn</a><br/>\nFind logs at: <code>./wandb/run-20211107_143223-rgrbldxn/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 06kwsg2b with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.635426549159432e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/06kwsg2b\" target=\"_blank\">silver-sweep-13</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ac5a03e03f74c5496718ca80ca28f25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7ce726740f647e28966e66ceb28b6b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1068beecd1e942dfab100d03bfed2cb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"787d998ee8584456b1b3f4fe42898747"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dec462fead04154942ca7bd5b98e8cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"825f10e357de444b89cb43d96b8e68c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5d617522e8408b9487d03ed26e5db2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fae629d335be419d9088140d1aeb1f0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ceab823d13146aca3c0c69ee0fae81a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54a008aa2c404b1ea22d878635099ddb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 4 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"924c4b3a55e64e03afc3316274889f8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6adedc9e85e34998ad65fd613ca20b34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 3017... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▆▆▇▇▅█▆▃▄▂▁▁▃▁▁▁</td></tr><tr><td>accuracy</td><td>▁▆▇▇█</td></tr><tr><td>eval_loss</td><td>▅▁▃▇█</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▇▇▇██</td></tr><tr><td>lr</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>mcc</td><td>▁▆▆▇█</td></tr><tr><td>train_loss</td><td>██▂▁▆</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.20788</td></tr><tr><td>accuracy</td><td>0.77164</td></tr><tr><td>eval_loss</td><td>0.77519</td></tr><tr><td>global_step</td><td>840</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.58089</td></tr><tr><td>train_loss</td><td>0.5058</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">silver-sweep-13</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/06kwsg2b\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/06kwsg2b</a><br/>\nFind logs at: <code>./wandb/run-20211107_143602-06kwsg2b/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w0dd5idp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.372143679995614e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/w0dd5idp\" target=\"_blank\">solar-sweep-14</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b1adacdefe44f61b666d5dc6152b460"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f96192e1cdc4be49ab8e951fdedea23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ff778698f144d8b9523e616c29df6b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"621f998ac7d64c78b84e6fc8c949415e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe1e9580d80c471ebf2e9db14c2aace2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dcbede5d34349748b54f19973140873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1c7336082a64874902f05b63587a2e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bf751ec5fa24d6e896b5bf8df443deb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4deb647aebed4a1193466e55ff31e036"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9428e9e095b34184a07c3d2bdb555691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 3408... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▃▄▄▃▆██▅▄▄▃▂</td></tr><tr><td>accuracy</td><td>▁▁▁▁</td></tr><tr><td>eval_loss</td><td>█▇▁▁</td></tr><tr><td>global_step</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇██</td></tr><tr><td>lr</td><td>█▇▇▆▆▅▅▄▃▃▂▂▁</td></tr><tr><td>mcc</td><td>▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁██▆</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.81795</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87176</td></tr><tr><td>global_step</td><td>672</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.95375</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">solar-sweep-14</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/w0dd5idp\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/w0dd5idp</a><br/>\nFind logs at: <code>./wandb/run-20211107_144439-w0dd5idp/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ez8m8b4a with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00017735635483522488\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/ez8m8b4a\" target=\"_blank\">summer-sweep-15</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645cb45f38ad4acc9ddc5b06cf521018"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f66b9ef071a7459583c21fa6f6879da4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f448b11efbe847cf9d4a595cfdf784c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff167101ecbc4e00a096257447838cc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b22dc5e5aad849baba6719ff17b11fce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b3fae0ee6bb4466a700972cd1e37f6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f339ea2bf209427a8ed1caab31529157"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc67ec702deb4dd9bfe36da909c1de2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 3743... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▄▅▆▃▆██▅▅</td></tr><tr><td>accuracy</td><td>▁▁▁</td></tr><tr><td>eval_loss</td><td>█▁▂</td></tr><tr><td>global_step</td><td>▁▂▃▃▃▄▅▅▆▆▇██</td></tr><tr><td>lr</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>mcc</td><td>▁▁▁</td></tr><tr><td>train_loss</td><td>▁▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.92188</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87854</td></tr><tr><td>global_step</td><td>504</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.09062</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">summer-sweep-15</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/ez8m8b4a\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/ez8m8b4a</a><br/>\nFind logs at: <code>./wandb/run-20211107_145138-ez8m8b4a/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mz3kkjbc with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002067821631865335\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/mz3kkjbc\" target=\"_blank\">desert-sweep-16</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\nSome weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49a2f604e8d94377a02aeb2160f57ab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07feda05ca554545a8089ff50ccd352b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6bfd3ae1e2d4161a4ff43ded91c9187"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6285e8ee07bd452fbff64ee11a6e917a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3832b45069b486996b566b7b7176a03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00d6fdc21e654db4b5d022582d2a939a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e61f0eb7a0a242c2803d2236dc7124cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0cf78f9b02c4016a838fd84abb6d442"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 4025... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▂▄▆▂▅██▄▄</td></tr><tr><td>accuracy</td><td>▁▁▁</td></tr><tr><td>eval_loss</td><td>█▆▁</td></tr><tr><td>global_step</td><td>▁▂▃▃▃▄▅▅▆▆▇██</td></tr><tr><td>lr</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>mcc</td><td>▁▁▁</td></tr><tr><td>train_loss</td><td>▁▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.91384</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.84542</td></tr><tr><td>global_step</td><td>504</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.02344</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">desert-sweep-16</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/mz3kkjbc\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/mz3kkjbc</a><br/>\nFind logs at: <code>./wandb/run-20211107_145658-mz3kkjbc/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xlbt7e97 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003296878105688984\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/xlbt7e97\" target=\"_blank\">genial-sweep-17</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be12e44f972f4ab8abe68ee5c83d83c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84582b50ec1546c094ae3eda4b9d935b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00a192d85ad44f2d97a3ee5ba25805b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287c43812c9a4b44921abd44e81e90a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"913479c71a934e499282023d089cad2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd2cfb1c712d4da2839cfd8c280fccf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c57e99c96a94458a28aa2f6718aa200"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aae777d1de2b4c26b6811ba69ab92198"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7402504b0f34cda9ad66992aac634c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d656165745c048d6acca7c5a5a4696a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 4 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24b84f9d13fd4f09bdcb2850b9550098"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5592c6a3f0c64bff8eacf425063e7ad5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 5 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"895aa88a2b4c4489a70b515fff25cc7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef4a203085ad466b88f13b57f5039113"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 4295... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▄▆▇▄▆█▇▅▅▄▄▄▅▄▆█▇▇▆</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁</td></tr><tr><td>eval_loss</td><td>▆█▁▂▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇███</td></tr><tr><td>lr</td><td>██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>mcc</td><td>▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁▄▄▃▂█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.97942</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87412</td></tr><tr><td>global_step</td><td>1008</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.11053</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">genial-sweep-17</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/xlbt7e97\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/xlbt7e97</a><br/>\nFind logs at: <code>./wandb/run-20211107_150217-xlbt7e97/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 92rldcaj with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.083334239412276e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/92rldcaj\" target=\"_blank\">clear-sweep-18</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38baaf4293ea430bb4f122ca8ea9ffa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9935ca38ef64e61bff55ef184b7263e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61f32a0f01064076b89a07aafb934060"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5d880f7a3c244d991c7831efb0c8fce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16884bd1813e4b25997b2e8928f5e517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de86b052d7144aae80ec76067c565054"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1729acd14664e3c85e564ea76770bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9deee9fd9fc4eba9fa956f45514f00d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed0c1f082b048f996d09c547d94adf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4711da8f0f457799b3913bee152390"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 4 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e919384363b4dadb09852628bf84292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a72141667f449cbdb91c82de955e78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 5 of 6:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b047c1c30845454498017b6848b86371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4d3b4991ee40d190e984216a5a0ec3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 4781... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▆▅█▆▆█▆▄▅▄▂▃▃▃▂▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▄▆▃█▆</td></tr><tr><td>eval_loss</td><td>▂▁▂▅▅█</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇███</td></tr><tr><td>lr</td><td>██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>mcc</td><td>▁▆▇▅█▅</td></tr><tr><td>train_loss</td><td>█▆▁▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.03847</td></tr><tr><td>accuracy</td><td>0.75373</td></tr><tr><td>eval_loss</td><td>1.03449</td></tr><tr><td>global_step</td><td>1008</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.53594</td></tr><tr><td>train_loss</td><td>0.28479</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">clear-sweep-18</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/92rldcaj\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/92rldcaj</a><br/>\nFind logs at: <code>./wandb/run-20211107_151235-92rldcaj/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bhbhif6d with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002011629978509094\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/bhbhif6d\" target=\"_blank\">crimson-sweep-19</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a44e1a6e592495d9027b1014907747d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04017529aa7b47c5ae268cbb0ce0d844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f82c024663474adcaf9ea74ba6f4871c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32e0d834b684497894733ff6c7d6f375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c71477159924570a678c5d338b91976"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f26665c6062a42bf94ed4de023fdea24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 5240... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▃▂▅▅▁█</td></tr><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.96208</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87124</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>2e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.01537</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">crimson-sweep-19</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/bhbhif6d\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/bhbhif6d</a><br/>\nFind logs at: <code>./wandb/run-20211107_152252-bhbhif6d/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pc1x7aw3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00019913078779785077\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/pc1x7aw3\" target=\"_blank\">volcanic-sweep-20</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdebe890769143939624f2095cda74e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d3bdaec431c46bb86b71d6ccef0af27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e8d5c054435482e82fb01c7dfa70289"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80617a5131e549f4b963d0077258484c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cfa175d5c6d4caa95fd000cb27cea62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8252571ee8b4407936f9662e959c8d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e1c8703ed040a5a2b80a2d611645f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6899c238282d4d77a7da7888ae2eff18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 5430... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▂▄▅▁▅██▄▄</td></tr><tr><td>accuracy</td><td>▁▁▁</td></tr><tr><td>eval_loss</td><td>█▁▁</td></tr><tr><td>global_step</td><td>▁▂▃▃▃▄▅▅▆▆▇██</td></tr><tr><td>lr</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>mcc</td><td>▁▁▁</td></tr><tr><td>train_loss</td><td>▁▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.93056</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87897</td></tr><tr><td>global_step</td><td>504</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.10349</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">volcanic-sweep-20</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/pc1x7aw3\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/pc1x7aw3</a><br/>\nFind logs at: <code>./wandb/run-20211107_152630-pc1x7aw3/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lav9ekic with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002996021139323079\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/lav9ekic\" target=\"_blank\">summer-sweep-21</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7f501a2e7154ee38dc623a872872a1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dc7ff7fe80348e6980b4f914099893e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42d60b554b2e4d898e33a6cd8eee69f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f665ca0d597a48e4af172defb6230f71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645628f27fd7495ebd5ab1a34682b4b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf617822d2e64d1bb78e8014337485d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2af00fb8c504fc3874f80c65569f75a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63a294a7d2304857ba1312a82793e741"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a550324cb9d421aba7d19b66ce41251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"982cd870f9d14a35bd659c43ace1fb2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 4 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3ecea0fecf34bab980945a117c2f7b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03d605eb4d0041a39f172f23f74cc259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 5685... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▃▅▇▃▅█▇▅▅▄▃▃▄▃▆</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>eval_loss</td><td>██▁▂▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▇▇▇██</td></tr><tr><td>lr</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>mcc</td><td>▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁█▇▆▃</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.99293</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87577</td></tr><tr><td>global_step</td><td>840</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.85617</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">summer-sweep-21</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/lav9ekic\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/lav9ekic</a><br/>\nFind logs at: <code>./wandb/run-20211107_153148-lav9ekic/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a1cyst37 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003755075032477262\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/a1cyst37\" target=\"_blank\">mild-sweep-22</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f1c7b18b1e547a8bf38d6e653326557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19cee17489494edb939edab627ed06da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"711e5a24ef0045c8a1f551316a4d12c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a7c6f9cc87640ccaf26a07f9d97bba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"164bef03bced493f81f89637c95dcbca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"425636a3d3f041599e8914b3e13c7617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 6080... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▄▆▁▇</td></tr><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.97042</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87289</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>4e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.00589</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">mild-sweep-22</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/a1cyst37\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/a1cyst37</a><br/>\nFind logs at: <code>./wandb/run-20211107_154025-a1cyst37/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k5cuzpm5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00027415811846809735\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/k5cuzpm5\" target=\"_blank\">hearty-sweep-23</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e133eb4a6a4e65bcb15a932cf21f1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb98b6e3fef14001a0380a3386665d29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c4c9a3694154441a5ee381325751a45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd0afdbc9194e9f84f672fbe8a27a21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96d00e2b327a4e0c98f3f75e1d90e813"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f96fc259814e91875ace412d95394c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 6281... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▃▃▆█▁█</td></tr><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.96252</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87173</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.00192</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">hearty-sweep-23</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/k5cuzpm5\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/k5cuzpm5</a><br/>\nFind logs at: <code>./wandb/run-20211107_154404-k5cuzpm5/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dw8g4stb with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00011046553652717888\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/dw8g4stb\" target=\"_blank\">ruby-sweep-24</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5a4e47e630d41d3affd3ef282945231"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6df2368c7dfb4647b730c5181f24d3eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c4ac0139c2842dbb77fe35935fb1d94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad158814bc8b44e8ad75287daac426fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ad9b93b7220483da1c1fc8ad9d4d8e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e18b9a82939491f888d83cfd116a002"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5423d102a6d4d4597f22b64a5e872e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f1667fe41ca47169bade642bcca6452"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a066d8db5ec4e218e24f505e29bf3a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d37facac3d5b4049b246725083b74f8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 6471... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▃▆▅▅▆█▅▄▃▂▂▃</td></tr><tr><td>accuracy</td><td>▂▁▇█</td></tr><tr><td>eval_loss</td><td>██▂▁</td></tr><tr><td>global_step</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇██</td></tr><tr><td>lr</td><td>█▇▇▆▆▅▄▄▃▃▂▂▁</td></tr><tr><td>mcc</td><td>▃▁██</td></tr><tr><td>train_loss</td><td>▂█▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.64248</td></tr><tr><td>accuracy</td><td>0.75075</td></tr><tr><td>eval_loss</td><td>0.66458</td></tr><tr><td>global_step</td><td>672</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mcc</td><td>0.50803</td></tr><tr><td>train_loss</td><td>0.66046</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">ruby-sweep-24</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/dw8g4stb\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/dw8g4stb</a><br/>\nFind logs at: <code>./wandb/run-20211107_154743-dw8g4stb/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d2ekpqxh with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00022141656811269596\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/d2ekpqxh\" target=\"_blank\">clean-sweep-25</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c74b6d32c1c4945b6067c32964148c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fe54e5781264539af73a53f1ac0575f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e7f1ca20c3349e18c546165d148b9f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"508829aae36442dfa0b2e498ff63230f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e8096d6f2704123af40abbd1f011367"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c48b536cd254ad7807c541dd6a446d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 6799... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▄▆▇▃█</td></tr><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>eval_loss</td><td>█▁</td></tr><tr><td>global_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>lr</td><td>█▇▅▄▂▁</td></tr><tr><td>mcc</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.9428</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.8708</td></tr><tr><td>global_step</td><td>336</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.01346</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">clean-sweep-25</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/d2ekpqxh\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/d2ekpqxh</a><br/>\nFind logs at: <code>./wandb/run-20211107_155442-d2ekpqxh/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rwk79wf3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00031447615041090167\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/rwk79wf3\" target=\"_blank\">crimson-sweep-26</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9eff8f28bc34fc099eb11968a69f140"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48bdf5cd14a043af87f508786c0dd74c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50ea961a871b4b0799c4b0b428bbfbe1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0989230cb20430d99682dd90736fa97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f587afe58c71434db0e134bd373a60c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"533666aebf1746fbb4a838c5c293e0ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99da6dece41f450f9cd3c834b2bf8bc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778c7614e4fa4f7a8d17a1e42fc5af66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4631d7b30f42adb94a3308f767a80d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"358deadbfba24782bba63f84d0676bef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 6995... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▄▆▇▄▆█▇▅▅▄▄▄</td></tr><tr><td>accuracy</td><td>▁▁▁▁</td></tr><tr><td>eval_loss</td><td>█▇▁▁</td></tr><tr><td>global_step</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇██</td></tr><tr><td>lr</td><td>█▇▇▆▆▅▅▄▃▃▂▂▁</td></tr><tr><td>mcc</td><td>▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁███</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.84515</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87201</td></tr><tr><td>global_step</td><td>672</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.97115</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">crimson-sweep-26</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/rwk79wf3\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/rwk79wf3</a><br/>\nFind logs at: <code>./wandb/run-20211107_155821-rwk79wf3/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n4qywume with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002563903847421804\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/n4qywume\" target=\"_blank\">denim-sweep-27</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d722a3d129374d0c86d2878d9abc1877"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8626305ea5d34ea29095bf9739465ec7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d00230a85847434393dbabcd998b073c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6acbf65a6a344c55ad9271f596b8d86c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"926df985eb2c43f8999956e591cf5fc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f523e2f04e9146cb960447883ce27972"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7916009962b349edb6856fa1ec8b4cf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23e831da67444eea8ac3e5202afdc274"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4feb02fc9ba4b9790cf11fd41edb935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99c5c9bfdd5540d1b7094475627fe252"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 4 of 5:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6b7ecc978c4d87a0cb30951796fa06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3d8e043404047f1a1b1d0f3f63404fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 7324... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▃▆▁▅█▇▄▄▂▂▂▄▁▅</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>eval_loss</td><td>▇█▁▂▂</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▇▇▇██</td></tr><tr><td>lr</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>mcc</td><td>▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁█▇▇▃</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.99122</td></tr><tr><td>accuracy</td><td>0.62537</td></tr><tr><td>eval_loss</td><td>0.87568</td></tr><tr><td>global_step</td><td>840</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mcc</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.86295</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">denim-sweep-27</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/n4qywume\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/n4qywume</a><br/>\nFind logs at: <code>./wandb/run-20211107_160518-n4qywume/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 04lg0vcy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002056369322188689\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/04lg0vcy\" target=\"_blank\">fiery-sweep-28</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 7726... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n</div><div class=\"wandb-col\">\n</div></div>\nSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">fiery-sweep-28</strong>: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/04lg0vcy\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/runs/04lg0vcy</a><br/>\nFind logs at: <code>./wandb/run-20211107_161358-04lg0vcy/logs</code><br/>\n"},"metadata":{}},{"name":"stderr","text":"Run 04lg0vcy errored: HTTPError('502 Server Error: Bad Gateway for url: https://huggingface.co/xlnet-base-cased/resolve/main/special_tokens_map.json')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 04lg0vcy errored: HTTPError('502 Server Error: Bad Gateway for url: https://huggingface.co/xlnet-base-cased/resolve/main/special_tokens_map.json')\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4wp82up3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001344966724268971\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\nCondaEnvException: Unable to determine environment\n\nPlease re-run this command with one of the following options:\n\n* Provide an environment name via --name or -n\n* Re-run this command inside an activated conda environment.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/datasiens/xlnet_original_train/runs/4wp82up3\" target=\"_blank\">volcanic-sweep-29</a></strong> to <a href=\"https://wandb.ai/datasiens/xlnet_original_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\nSweep page: <a href=\"https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6\" target=\"_blank\">https://wandb.ai/datasiens/xlnet_original_train/sweeps/bylsapm6</a><br/>\n\n                "},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5360 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afff0e58b2ac445681baf2c733868569"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ffc4a1b6845483788d8ec3b7ff21c1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb8c921229642fda2ec484ea93af591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8dfdda37a2f4cee83eba8bf100438c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46828e5d0d7e44b9b07c9e0075e0c01a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/670 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c001c7e68bda4997ac8bf7a694db723a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 4:   0%|          | 0/168 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16e63f6c42b7402eb9b8fc112e8ae64c"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"}]}]}